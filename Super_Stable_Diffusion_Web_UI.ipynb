{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/Super-Stable-Diffusion-Web-UI/blob/main/Super_Stable_Diffusion_Web_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Super Stable Diffusion\n",
        "### Expected to be released on December 1, 2022"
      ],
      "metadata": {
        "id": "OAsjydyqJual"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBDPqhYnyBL1"
      },
      "source": [
        "## I. Memory and GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woQCdVO8x-Kt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Memory Information\n",
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPU Information\n",
        "from IPython.display import HTML\n",
        "from subprocess import getoutput\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'K80' in s:\n",
        "  gpu = 'K80'\n",
        "elif 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "display(HTML(f\"<h2>{gpu}</h2>\"))\n",
        "print(s)"
      ],
      "metadata": {
        "id": "aKm9rr7NAFE9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Installation"
      ],
      "metadata": {
        "id": "6rtaqBh32oE9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBbcB4vwj_jm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone Web UI Repository\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will clone Automatic1111's Stable Diffusion Web UI repository, if the folder already exists it will do a !git pull instead.\n",
        "\n",
        "#@markdown Run this code everytime you want to !git pull  to get a lot of new optimizations and updates.\n",
        "import os\n",
        "\n",
        "if os.path.isdir('/content/stable-diffusion-webui'):\n",
        "  %cd /content/stable-diffusion-webui\n",
        "  print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "  !git pull\n",
        "  \n",
        "else:\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will install all requirement needed for Stable Diffusion Web UI from requirement.txt and also install some dependencies from other sources.\n",
        "%cd /content/stable-diffusion-webui\n",
        "!pip install -r requirements.txt\n",
        "!pip install pytorch_lightning\n",
        "!pip3 install triton\n"
      ],
      "metadata": {
        "id": "ZKmjquWARi2H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Downloadable Content"
      ],
      "metadata": {
        "id": "GZ8ymrQcTaAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Checkpoint\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will download the Stable Diffusion checkpoint/model (.ckpt) you selected from the checkbox.\n",
        "#@markdown You can also add your own checkpoint in the template provided.\n",
        "import os\n",
        "import time\n",
        "\n",
        "def huggingface_checkpoint(url, checkpoint_name):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt\n",
        "\n",
        "def custom_checkpoint(url, checkpoint_name):\n",
        "  !wget {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  #@markdown Choose the models you want:\n",
        "  Animefull_Final_Pruned= True #@param {'type':'boolean'}\n",
        "  AnimeSFW_Final_Pruned= False #@param {'type':'boolean'}\n",
        "  Waifu_Diffusion_V1_3 = True #@param {'type':'boolean'}\n",
        "  Stable_Diffusion_V1_5 = False #@param {'type':'boolean'}\n",
        "  Stable_Diffusion_V1_5_Inpainting = False #@param {'type':'boolean'}\n",
        "  Trinart2_Step115000= True #@param {'type':'boolean'}\n",
        "  Anything_V3_0 = False #@param {'type':'boolean'}\n",
        "  Anything_V2_1 = False #@param {'type':'boolean'}\n",
        "  Anything_V3_0_Pruned = True #@param {'type':'boolean'}\n",
        "  Anything_V2_1_Pruned = False #@param {'type':'boolean'}\n",
        "  #YOUR_HUGGINGFACE_CHECKPOINT_HERE = False #@param {'type':'boolean'}\n",
        "  #YOUR_CUSTOM_CHECKPOINT_HERE = False #@param {'type':'boolean'}\n",
        "\n",
        "  if Animefull_Final_Pruned:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \"Animefull_Final_Pruned\")\n",
        "  if AnimeSFW_Final_Pruned:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/modelsfw-pruned.ckpt\", \"AnimeSFW_Final_Pruned\")\n",
        "  if Waifu_Diffusion_V1_3:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\", \"Waifu_Diffusion_V1_3\")\n",
        "  if Stable_Diffusion_V1_5:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \"Stable_Diffusion_V1_5\")\n",
        "  if Stable_Diffusion_V1_5_Inpainting:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt\", \"Stable_Diffusion_V1_5_Inpainting\")\n",
        "  if Trinart2_Step115000:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step115000.ckpt\", \"Trinart2_Step115000\")\n",
        "  if Anything_V3_0:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/unpickled-version/Anything-V3.0.ckpt\", \"Anything_V3_0\")\n",
        "  if Anything_V2_1:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v2.1/resolve/main/Anything-V2.1.ckpt\", \"Anything_V2_1\")\n",
        "  if Anything_V3_0_Pruned:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/unpickled-version/Anything-V3.0-pruned.ckpt\", \"Anything_V3_0_Pruned\")\n",
        "  if Anything_V2_1_Pruned:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v2.1/resolve/main/Anything-V2.1-pruned.ckpt\", \"Anything_V2_1_Pruned\")\n",
        "  #if YOUR_HUGGINGFACE_CHECKPOINT_HERE:\n",
        "  #  huggingface_checkpoint(\"URL\", \"YOUR_HUGGINGFACE_CHECKPOINT_HERE\")\n",
        "  #if YOUR_CUSTOM_CHECKPOINT_HERE:\n",
        "  #  custom_checkpoint(\"URL\", \"YOUR_CUSTOM_CHECKPOINT_HERE\")\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "wdIgWyY19Kvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Checkpoint\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code is for launch Web UI. You will get a link to nnn.gradio.app, follow it.\n",
        "#@markdown You can either change the config below or just run it.\n",
        "!npm install -g localtunnel\n",
        "vae_args = \"\"\n",
        "from subprocess import getoutput\n",
        "\n",
        "def install_xformers():\n",
        "  s = getoutput('nvidia-smi')\n",
        "  if 'T4' in s:\n",
        "    gpu = 'T4'\n",
        "  elif 'P100' in s:\n",
        "    gpu = 'P100'\n",
        "  elif 'V100' in s:\n",
        "    gpu = 'V100'\n",
        "  elif 'A100' in s:\n",
        "    gpu = 'A100'\n",
        "  else:\n",
        "    print(\"Your GPU sucks...\")\n",
        "    exit()\n",
        "\n",
        "  if (gpu=='T4'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "    \n",
        "  elif (gpu=='P100'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "  elif (gpu=='V100'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "  elif (gpu=='A100'):\n",
        "    %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "def huggingface_vae(url, vae):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{vae}\n",
        "\n",
        "def custom_vae(url, vae):\n",
        "  !wget {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{vae}.pt\n",
        "\n",
        "def run_webui():\n",
        "  Anime_VAE= True #@param {'type':'boolean'}\n",
        "  Stable_Diffusion_V1_5_VAE = False #@param {'type':'boolean'}\n",
        "  Waifu_Diffusion_V1_4_VAE = False #@param {'type':'boolean'}\n",
        "  #YOUR_HUGGINGFACE_VAE_HERE = False #@param {'type':'boolean'}\n",
        "  #YOUR_CUSTOM_VAE_HERE = False #@param {'type':'boolean'}\n",
        "  if Anime_VAE:\n",
        "    huggingface_vae(\"https://huggingface.co/Linaqruf/checkpoint_database/resolve/main/animevae/animevae.pt\", \"animevae.pt\")\n",
        "    vae_args = \"--vae-path /content/stable-diffusion-webui/models/Stable-diffusion/animevae.pt\"\n",
        "  if Waifu_Diffusion_V1_4_VAE_Pruned:\n",
        "    huggingface_vae(\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\", \"Waifu_Diffusion_V1_4.vae.pt\")\n",
        "    vae_args = \"--vae-path /content/stable-diffusion-webui/models/Stable-diffusion/Waifu_Diffusion_V1_4.vae.pt\"\n",
        "  if Stable_Diffusion_V1_5_VAE:\n",
        "    huggingface_vae(\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\", \"Stable_Diffusion_V1_5.vae.pt\")\n",
        "    vae_args = \"--vae-path /content/stable-diffusion-webui/models/Stable-diffusion/Stable_Diffusion_V1_5.vae.pt\"\n",
        "\n",
        "  #if YOUR_HUGGINGFACE_VAE_HERE:\n",
        "  #  huggingface_vae(\"URL\", \"YOUR_HUGGINGFACE_VAE_HERE\")\n",
        "  #if YOUR_CUSTOM_VAE_HERE:\n",
        "  #  custom_vae(\"URL\", \"YOUR_CUSTOM_VAE_HERE\")\n",
        "\n",
        "\n",
        "  %cd /content/stable-diffusion-webui/\n",
        "  xformers = \"\"\n",
        "  vram = \"--medvram\" #@param [\"--medvram\", \"--lowvram\", \"\"]\n",
        "  other_args = \"--deepdanbooru --no-half-vae --gradio-debug --disable-safe-unpickle\" #@param {type:\"string\"}\n",
        "  gradio_username = \"webui\" #@param {'type': 'string'}\n",
        "  gradio_password = \"diffusion\" #@param {'type': 'string'}\n",
        "  use_xformers = False #@param {'type':'boolean'}\n",
        "  if use_xformers:\n",
        "   xformers = \"--xformers\"\n",
        "   install_xformers() \n",
        "  use_localtunnel = False #@param{type:\"boolean\"}\n",
        "  if use_localtunnel == True:\n",
        "    !nohup lt -p 7860 > lt.log 2>&1 &  \n",
        "    time.sleep(2)\n",
        "    with open('/content/stable-diffusion-webui/lt.log', 'r') as testwritefile:\n",
        "      print(\"\\033[92m\" + \"Wait for the model to load and follow this link\")\n",
        "      print(testwritefile.read())\n",
        "      print(\"\\033[95m\")\n",
        "      !COMMANDLINE_ARGS=\"{xformers} {other_args} {vae_args} {vram} --gradio-auth {gradio_username}:{gradio_password}\" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "  else:\n",
        "      !COMMANDLINE_ARGS=\"--share {xformers} {other_args} {vae_args} {vram} --gradio-auth {gradio_username}:{gradio_password} \" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "  \n",
        "\n",
        "run_webui()\n",
        "#@markdown ### Glossary:\n",
        "\n",
        "#@markdown 1. **VAE** or  **Variational autoencoders (VAEs)** are a deep learning technique for learning latent representations. Basically a filter that can changes output. You can get better face, hand and eyes. Is generally good, but seems to dull color (Animevae case)\n",
        "#@markdown 2. `--medvram` use 4GB VRAM, `--lowvram` use 2GB VRAM, if you're using colab pro you can leave this empty.\n",
        "#@markdown 3. `--share` is an args for sharing gradio app link, so you can use gradio app link on different device or even you can give it to your friend. If you leave it empty, webui using localtunnel instead.\n",
        "#@markdown 4. `--deepdanbooru` is an autotagger. The AI automatically finds Danbooru tags that it thinks matches the picture it's given. \n",
        "#@markdown 5. `--no-half-vae` is an args to fix the black renders. It still occasionally shows a black preview but the finished render (or interrupted render) is complete.\n",
        "#@markdown 6. `--gradio-debug` is to print outputs to console\n",
        "#@markdown 4. You can set `username` and `password` to gradio so people cannot access your gradio app without your consent.\n",
        "#@markdown 5. `--xformers` increases the generation speed by 1.5 - 3 times, on T4 the generation speed increases by 1.5 times"
      ],
      "metadata": {
        "id": "5y373VgxfRtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Explanation:\n",
        "#@title Load Checkpoint From Google Drive (optional)\n",
        "#@markdown if you want to load custom checkpoint from your Google Drive, you can check this option.\n",
        "#@markdown The checkpoint will not be downloaded, but copied from your drive.\n",
        "mount_gdrive = False #@param{type:\"boolean\"}\n",
        "gdrive_path = \"checkpoint/Waifu_Diffusion_V1_4.ckpt\" #@param {type:\"string\"}\n",
        "#@markdown Your path look like /content/drive/MyDrive/**gdrive_path**\n",
        "\n",
        "if mount_gdrive == True or mount_gdrive_for_outputs == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "if mount_gdrive == True:\n",
        "  new_gdrive_path = \"/content/drive/MyDrive/\" + gdrive_path\n",
        "  !cp $new_gdrive_path /content/stable-diffusion-webui/models/model.ckpt\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tYrR4X3OX1Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCtJffM2ZE06"
      },
      "source": [
        "Zip images for downloading on local drive (click the folder icon on the left, the one below {x})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmRqNyiAZCHu"
      },
      "outputs": [],
      "source": [
        "%cd /content/stable-diffusion-webui/\n",
        "!zip -r /content/stable-diffusion-webui outputs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcslU-S2ZNr9"
      },
      "source": [
        "Save images to Google Drive **Warning: this will cause google to scan your drive, so if you intend to use this and worry about that kind of stuff, probablly just set this up on a clean account that's just for this colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N0lnu-TZOTW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive # type: ignore\n",
        "\n",
        "try:\n",
        "   drive_path = \"/content/drive\"\n",
        "   drive.mount(drive_path,force_remount=False)\n",
        "except:\n",
        "   print(\"...error mounting drive or with drive path variables\")\n",
        "\n",
        "!cp -r \"/content/stable-diffusion-webui/outputs\" \"/content/drive/MyDrive\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VBDPqhYnyBL1"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}