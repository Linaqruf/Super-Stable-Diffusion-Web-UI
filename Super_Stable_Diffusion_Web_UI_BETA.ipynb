{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/Super-Stable-Diffusion-Web-UI/blob/main/Super_Stable_Diffusion_Web_UI_BETA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Super Stable Diffusion\n",
        "### Expected to be released on December 1, 2022"
      ],
      "metadata": {
        "id": "OAsjydyqJual"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBDPqhYnyBL1"
      },
      "source": [
        "## I. Memory and GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woQCdVO8x-Kt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Memory Information\n",
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPU Information\n",
        "from IPython.display import HTML\n",
        "from subprocess import getoutput\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'K80' in s:\n",
        "  gpu = 'K80'\n",
        "elif 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "display(HTML(f\"<h2>{gpu}</h2>\"))\n",
        "print(s)"
      ],
      "metadata": {
        "id": "aKm9rr7NAFE9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Installation"
      ],
      "metadata": {
        "id": "6rtaqBh32oE9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBbcB4vwj_jm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone Web UI Repository\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will clone Automatic1111's Stable Diffusion Web UI repository, if the folder already exists it will do a !git pull instead.\n",
        "\n",
        "#@markdown Run this code everytime you want to !git pull  to get a lot of new optimizations and updates.\n",
        "import os\n",
        "%cd /content/\n",
        "if os.path.isdir('/content/stable-diffusion-webui'):\n",
        "  %cd /content/stable-diffusion-webui\n",
        "  print(\"This folder already exists, will do a !git pull instead\\n\")\n",
        "  !git pull\n",
        "  \n",
        "else:\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will install all requirement needed for Stable Diffusion Web UI from requirement.txt and also install some dependencies from other sources.\n",
        "%cd /content/stable-diffusion-webui\n",
        "!pip install -r requirements.txt\n",
        "!pip install pytorch_lightning\n"
      ],
      "metadata": {
        "id": "ZKmjquWARi2H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##II. Downloadable Content"
      ],
      "metadata": {
        "id": "GZ8ymrQcTaAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Available Checkpoint\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will download the Stable Diffusion checkpoint/model (.ckpt) you selected from the checkbox.\n",
        "#@markdown You can also add your own checkpoint in the template provided.\n",
        "\n",
        "def huggingface_checkpoint(url, checkpoint_name):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt\n",
        "\n",
        "def custom_checkpoint(url, checkpoint_name):\n",
        "  !wget {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  #@markdown Choose the models you want:\n",
        "  Animefull_Final_Pruned= True #@param {'type':'boolean'}\n",
        "  AnimeSFW_Final_Pruned= False #@param {'type':'boolean'}\n",
        "  Waifu_Diffusion_V1_3 = True #@param {'type':'boolean'}\n",
        "  Stable_Diffusion_V1_5 = False #@param {'type':'boolean'}\n",
        "  Stable_Diffusion_V1_5_Inpainting = False #@param {'type':'boolean'}\n",
        "  Trinart2_Step115000= True #@param {'type':'boolean'}\n",
        "  AnythingV2_1_Pruned = False #@param {'type':'boolean'}\n",
        "  AnythingV3_Pruned = True #@param {'type':'boolean'}\n",
        "  Trinart_Characters_it4_V1 = True #@param {'type':'boolean'}\n",
        "\n",
        "  #YOUR_HUGGINGFACE_CHECKPOINT_HERE = False #@param {'type':'boolean'}\n",
        "  #YOUR_CUSTOM_CHECKPOINT_HERE = False #@param {'type':'boolean'}\n",
        "\n",
        "  if Animefull_Final_Pruned:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \"Animefull_Final_Pruned\")\n",
        "  if AnimeSFW_Final_Pruned:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/modelsfw-pruned.ckpt\", \"AnimeSFW_Final_Pruned\")\n",
        "  if Waifu_Diffusion_V1_3:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\", \"Waifu_Diffusion_V1_3\")\n",
        "  if Stable_Diffusion_V1_5:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \"Stable_Diffusion_V1_5\")\n",
        "  if Stable_Diffusion_V1_5_Inpainting:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt\", \"Stable_Diffusion_V1_5_Inpainting\")\n",
        "  if Trinart2_Step115000:\n",
        "    huggingface_checkpoint(\"https://huggingface.co/naclbit/trinart_stable_diffusion_v2/resolve/main/trinart2_step115000.ckpt\", \"Trinart2_Step115000\")\n",
        "  if AnythingV3_Pruned:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \"Anything_V3_Pruned\")\n",
        "  if AnythingV2_1_Pruned:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/Linaqruf/anything-v2.1/resolve/main/Anything-V2.1-pruned.ckpt\", \"Anything_V2_1_Pruned\")\n",
        "  if Trinart_Characters_it4_V1:\n",
        "   huggingface_checkpoint(\"https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/trinart_characters_it4_v1.ckpt\", \"Trinart_Characters_it4_V1\")\n",
        " \n",
        "  #if YOUR_HUGGINGFACE_CHECKPOINT_HERE:\n",
        "  #  huggingface_checkpoint(\"URL\", \"YOUR_HUGGINGFACE_CHECKPOINT_HERE\")\n",
        "  #if YOUR_CUSTOM_CHECKPOINT_HERE:\n",
        "  #  custom_checkpoint(\"URL\", \"YOUR_CUSTOM_CHECKPOINT_HERE\")\n",
        "\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "wdIgWyY19Kvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Custom Checkpoint\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code will download the Stable Diffusion checkpoint/model (.ckpt) you selected from the checkbox.\n",
        "#@markdown You can also add your own checkpoint in the template provided.\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  modelName1 = \"Waifu_Diffusion_1_4_Demo\" #@param {'type': 'string'}\n",
        "  modelURL1 = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/models/wd-1-3-penultimate-ucg-cont.ckpt\" #@param {'type': 'string'}\n",
        "\n",
        "  modelName2 = \"Hiten\" #@param {'type': 'string'}\n",
        "  modelURL2 = \"https://huggingface.co/BumblingOrange/Hiten/resolve/main/Hiten%20girl_anime_8k_wallpaper_4k.ckpt\" #@param {'type': 'string'}\n",
        "\n",
        "\n",
        "  def custom_checkpoint(url, checkpointName):\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    !wget -c --header={user_header} {url} -O /content/stable-diffusion-webui/models/Stable-diffusion/{checkpointName}.ckpt\n",
        "\n",
        "  def install_checkpoint():\n",
        "    custom_checkpoint(modelURL1, modelName1)\n",
        "    custom_checkpoint(modelURL2, modelName2)\n",
        "\n",
        "  install_checkpoint()\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qFq2afRIDTVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Explanation:\n",
        "#@markdown This code will download the Stable Diffusion checkpoint/model (.ckpt) you selected from the checkbox.\n",
        "#@markdown You can also add your own checkpoint in the template provided.\n",
        "\n",
        "%cd /content/stable-diffusion-webui/models/Stable-diffusion/\n",
        "\n",
        "#@title Download VAE\n",
        "Anime_VAE= True #@param {'type':'boolean'}\n",
        "Stable_Diffusion_V1_5_VAE = False #@param {'type':'boolean'}\n",
        "Waifu_Diffusion_V1_4_VAE_Pruned = True #@param {'type':'boolean'}\n",
        "\n",
        "def wget(vaeUrl, vaeName):\n",
        "  !wget {vaeUrl} -O {vaeName}.pt\n",
        "\n",
        "def custom_wget():\n",
        "  wget(vaeUrl, vaeName)\n",
        "\n",
        "#@markdown Download Custom VAE \n",
        "opt_out = False #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  custom_wget()\n",
        "\n",
        "vaeName = \"Trinart_characters\" #@param {'type': 'string'}\n",
        "vaeUrl = \"https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/autoencoder_fix_kl-f8-trinart_characters.ckpt\" #@param {'type': 'string'}\n",
        "\n",
        "if Anime_VAE:\n",
        "  wget(\"https://huggingface.co/Linaqruf/checkpoint_database/resolve/main/animevae/animevae.pt\", \"anime.vae.pt\")\n",
        "if Waifu_Diffusion_V1_4_VAE_Pruned:\n",
        "  wget(\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\", \"Waifu_Diffusion_V1_4.vae.pt\")\n",
        "if Stable_Diffusion_V1_5_VAE:\n",
        "  wget(\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\", \"Stable_Diffusion_V1_5.vae.pt\")\n",
        "#@markdown ### Glossary:\n",
        "\n",
        "#@markdown 1. **VAE** or  **Variational autoencoders (VAEs)** are a deep learning technique for learning latent representations. Basically a filter that can changes output. You can get better face, hand and eyes. Is generally good, but seems to dull color (Animevae case)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k8MR4OTFZyK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##III. Launch Web UI"
      ],
      "metadata": {
        "id": "2xWFb7I_AA5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure ARGS\n",
        "\n",
        "#@markdown # Explanation:\n",
        "#@markdown This code is for launch Web UI. You will get a link to nnn.gradio.app, follow it.\n",
        "#@markdown You can either change the config below or just run it.\n",
        "%cd /content/stable-diffusion-webui/\n",
        "!npm install -g localtunnel\n",
        "import time\n",
        "\n",
        "def run_webui():\n",
        "  vram = \"--medvram\" #@param [\"--medvram\", \"--lowvram\", \"\"]\n",
        "  other_args = \"--deepdanbooru --precision full --no-half --no-half-vae --gradio-debug --disable-safe-unpickle\" #@param {type:\"string\"}\n",
        "  gradio_username = \"webui\" #@param {'type': 'string'}\n",
        "  gradio_password = \"diffusion\" #@param {'type': 'string'}\n",
        "  custom_launch = \"use_share\" #@param [\"use_share\", \"use_ngrok\", \"use_localtunnel\"]\n",
        "  #@markdown Fill this option if you are using ngrok to run webui\n",
        "  ngrok_token = \"21LivrtppguTD5zg38bjy2ozvNR_3wrah825hvgoQTaoM7UgH\" #@param {'type': 'string'}\n",
        "\n",
        "  if custom_launch==\"use_share\":\n",
        "    print(\"\\033[93m\")\n",
        "    !COMMANDLINE_ARGS=\"--share {other_args} {vram} --gradio-auth {gradio_username}:{gradio_password} \" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "  \n",
        "  elif custom_launch==\"use_localtunnel\":\n",
        "    !npm install -g localtunnel\n",
        "    !nohup lt -p 7860 > lt.log 2>&1 &  \n",
        "    time.sleep(2)\n",
        "    with open('/content/stable-diffusion-webui/lt.log', 'r') as testwritefile:\n",
        "      print(\"\\033[92m\" + \"Wait for the model to load and follow this link\")\n",
        "      print(testwritefile.read())\n",
        "      print(\"\\033[95m\")\n",
        "      !COMMANDLINE_ARGS=\"{other_args} {vram} --gradio-auth {gradio_username}:{gradio_password}\" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "\n",
        "  elif custom_launch==\"use_ngrok\":\n",
        "    print(\"\\033[92m\")\n",
        "    !COMMANDLINE_ARGS=\"{other_args} {vram} --gradio-auth {gradio_username}:{gradio_password} --ngrok {ngrok_token}\"  REQS_FILE=\"requirements.txt\" python launch.py\n",
        "\n",
        "run_webui()\n",
        "#@markdown ### Glossary:\n",
        "\n",
        "#@markdown 1. `--medvram` use 4GB VRAM, `--lowvram` use 2GB VRAM, if you're using colab pro you can leave this empty.\n",
        "#@markdown 2. `--share` is an args for sharing gradio app link, so you can use gradio app link on different device or even you can give it to your friend. If you leave it empty, webui using localtunnel instead.\n",
        "#@markdown 3. `--deepdanbooru` is an autotagger. The AI automatically finds Danbooru tags that it thinks matches the picture it's given. \n",
        "#@markdown 4. `--no-half-vae` is an args to fix the black renders. It still occasionally shows a black preview but the finished render (or interrupted render) is complete.\n",
        "#@markdown 5. `--gradio-debug` is to print outputs to console\n",
        "#@markdown 6. You can set `username` and `password` to gradio so people cannot access your gradio app without your consent.\n",
        "#@markdown 7. `--xformers` increases the generation speed by 1.5 - 3 times, on T4 the generation speed increases by 1.5 times"
      ],
      "metadata": {
        "id": "5y373VgxfRtD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IV. Output"
      ],
      "metadata": {
        "id": "moq1FLNeCfrz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmRqNyiAZCHu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download Output\n",
        "%cd /content/stable-diffusion-webui/\n",
        "!zip -r /content/output.zip outputs\n",
        "\n",
        "!pip3 install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "def create_folder(folder_name):\n",
        "    # Check if folder exists\n",
        "    file_list = drive.ListFile({'q': \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(folder_name)}).GetList()\n",
        "    if len(file_list) > 0:\n",
        "        # Folder exists\n",
        "        print('Debug: Folder exists')\n",
        "        folder_id = file_list[0]['id']\n",
        "    else:\n",
        "        print('Debug: Creating folder')\n",
        "        file = drive.CreateFile({'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder'})\n",
        "        file.Upload()\n",
        "        folder_id = file.attr['metadata']['id']\n",
        "    # return folder id\n",
        "    return folder_id\n",
        "# Upload file to Google Drive\n",
        "def upload_file(file_name, folder_id, save_as):\n",
        "    # Check if file exists\n",
        "    file_list = drive.ListFile({'q': \"title='{}' and trashed=false\".format(save_as)}).GetList()\n",
        "    if len(file_list) > 0:\n",
        "        print('Debug: File already exists')\n",
        "        # Change file name to avoid overwriting\n",
        "        save_as = save_as + ' (1)'\n",
        "    file = drive.CreateFile({'title': save_as, 'parents': [{'id': folder_id}]})\n",
        "    file.SetContentFile(file_name)\n",
        "    # Upload and set permission to public\n",
        "    file.Upload()\n",
        "    file.InsertPermission({'type': 'anyone', 'value': 'anyone', 'role': 'reader'})\n",
        "    # return file id\n",
        "    return file.attr['metadata']['id']\n",
        "\n",
        "save_to_drive = True #@param {type:\"boolean\"}\n",
        "folder_name = \"AI_Illustration\" #@param {type: \"string\"}\n",
        "save_as = \"Output.zip\" #@param {type: \"string\"}\n",
        "\n",
        "if save_to_drive:\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  file_id = upload_file('/content/output.zip', create_folder(folder_name), save_as)\n",
        "  print(\"Your sharing link: https://drive.google.com/file/d/\" + file_id + \"/view?usp=sharing\")  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clean output folder\n",
        "from IPython.core.display import HTML\n",
        "#@markdown You can delete all of your output at /content/stable-diffusion-webui/outputs by running this cell\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "if opt_out == False:\n",
        "  %cd /content/stable-diffusion-webui\n",
        "\n",
        "  !rm -rf outputs\n",
        "  !mkdir -p outputs\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uTxCWGpFA-LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##V. Commit merged model to Huggingface"
      ],
      "metadata": {
        "id": "jypUkLWc48R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Model\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= False #@param {'type':'boolean'}\n",
        "\n",
        "\n",
        "if opt_out == False:\n",
        "  !pip install huggingface_hub\n",
        "\n",
        "  %cd /content\n",
        "  #@markdown Prepare your Huggingface token.\n",
        "  copy_this= \"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\" #@param {'type': 'string'}\n",
        "\n",
        "  from huggingface_hub import notebook_login\n",
        "\n",
        "  notebook_login()\n",
        "\n",
        "  Repository_url = \"https://huggingface.co/Linaqruf/merged-model-backup\" #@param {'type': 'string'}\n",
        "  !git clone {Repository_url}\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JYmi7nC75JMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= False #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  #@markdown Go to your model path\n",
        "  model_path= \"merged-model-backup\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**model_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"furqanil.taqwa@gmail.com\" #@param {'type': 'string'}\n",
        "  name= \"Linaqruf\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"Push: Rename Merged Model\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{model_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  display(HTML(f\"<h1>This cell will not running because you choose to opt-out this cell.<h1>\"))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-YPbXobD5MB6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VBDPqhYnyBL1"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}